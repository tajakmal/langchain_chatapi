{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain ChatAPI\n",
    "https://www.youtube.com/watch?v=e9P7FLi5Zy8&t=65s&ab_channel=DataIndependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "# environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize openai API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Simple Input/Output Still works\n",
    "You just need to pass it as a message instead. More on this in a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "#     model_name=\"gpt-3.5-turbo\", # Cheaper but less reliable\n",
    "    model_name=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# Initialize with Langchain\n",
    "#chat = llm(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The most populous state in the USA is California.', additional_kwargs={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = [HumanMessage(content=\"What is the name of the most populous state in the USA?\")]\n",
    "\n",
    "chat(message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chat Messages\n",
    "* HumanMessage: A message sent from the perspective of the human\n",
    "* AIMessage: A message sent from the perspective of the AI the human is interacting with\n",
    "* SystemMessage: A message setting the objectives the AI should follow\n",
    "* ChatMessage: A message allowing for arbitrary setting of role. You wonâ€™t be using this too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I hate programming.', additional_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Say the opposite of what the user says\"),\n",
    "    HumanMessage(content=\"I love programming.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The moon is not out.', additional_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Say the opposite of what the user says\"),\n",
    "    HumanMessage(content=\"I love programming.\"),\n",
    "    AIMessage(content='I hate programming.'),\n",
    "    HumanMessage(content=\"The moon is out\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said, \"I love programming.\"', additional_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Say the opposite of what the user says\"),\n",
    "    HumanMessage(content=\"I love programming.\"),\n",
    "    AIMessage(content='I hate programming.'),\n",
    "    HumanMessage(content=\"What is the first thing that I said?\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Apples are awesome autumn treats.', generation_info=None, message=AIMessage(content='Apples are awesome autumn treats.', additional_kwargs={}))], [ChatGeneration(text='Daring doggie dug deep.', generation_info=None, message=AIMessage(content='Daring doggie dug deep.', additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 64, 'completion_tokens': 14, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful word machine that creates an alliteration using a base word\"),\n",
    "        HumanMessage(content=\"Base word: Apple\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful word machine that creates an alliteration using a base word\"),\n",
    "        HumanMessage(content=\"Base word: Dog\")\n",
    "    ],\n",
    "]\n",
    "chat.generate(batch_messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "\n",
    "With one or more `MessagePromptTemplates` you can build a `ChatPromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make SystemMessagePromptTemplate\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Propose creative ways to incorporate {food_1} and {food_2} in the cuisine of the users choice.\",\n",
    "    input_variables=[\"food_1\", \"food_2\"]\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='Propose creative ways to incorporate Bacon and Shrimp in the cuisine of the users choice.', additional_kwargs={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of system_message_prompt\n",
    "system_message_prompt.format(food_1=\"Bacon\", food_2=\"Shrimp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make HumanMessagePromptTemplate\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['food_2', 'text', 'food_1'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['food_1', 'food_2'], output_parser=None, partial_variables={}, template='Propose creative ways to incorporate {food_1} and {food_2} in the cuisine of the users choice.', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='{text}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ChatPromptTemplate: Combine System + Human\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Propose creative ways to incorporate Bacon and Shrimp in the cuisine of the users choice.', additional_kwargs={}),\n",
       " HumanMessage(content='I really like food from Germany.', additional_kwargs={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_with_values = chat_prompt.format_prompt(food_1=\"Bacon\", \\\n",
    "                                                   food_2=\"Shrimp\", \\\n",
    "                                                   text=\"I really like food from Germany.\")\n",
    "\n",
    "chat_prompt_with_values.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Here are three creative ways to incorporate bacon and shrimp into German cuisine:\n",
      "\n",
      "1. Bacon-wrapped shrimp skewers: Marinate raw shrimp in olive oil, garlic, and lemon juice for at least 30 minutes. Cut bacon into thin strips and wrap each shrimp with a slice of bacon. Thread the bacon-wrapped shrimp onto skewers and grill until the bacon is crispy and the shrimp is cooked through. Serve with a side of sauerkraut and potato salad for a delicious and hearty German meal.\n",
      "\n",
      "2. Shrimp and bacon potato soup: Cook diced bacon in a large pot until crispy. Remove the bacon from the pot and set it aside. In the same pot, sautÃ© chopped onion, celery, and carrots until softened. Add diced potatoes, chicken broth, and thyme to the pot and simmer until the potatoes are tender. Stir in cooked shrimp and the reserved bacon and simmer for a few more minutes until the shrimp is heated through. Serve with a slice of hearty German bread for a comforting meal.\n",
      "\n",
      "3. Bacon and shrimp spaetzle: Cook spaetzle according to package instructions. While the spaetzle is cooking, sautÃ© chopped bacon in a large skillet until crispy. Remove the bacon from the skillet and set it aside. In the same skillet, sautÃ© peeled and deveined shrimp until cooked through. Toss the cooked spaetzle with the bacon and shrimp, along with a tablespoon of butter and some chopped parsley. Serve as a main dish or as a side with roasted pork or chicken for a flavorful German meal.\n"
     ]
    }
   ],
   "source": [
    "response = chat(chat_prompt_with_values.to_messages()).content\n",
    "print (response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Here are some creative ways to incorporate bacon and shrimp into German cuisine:\n",
      "\n",
      "1. Bacon and Shrimp SpÃ¤tzle: SpÃ¤tzle is a traditional German egg noodle dish. Add cooked shrimp and crispy bacon to the spÃ¤tzle and toss with butter and herbs for a delicious and hearty meal.\n",
      "\n",
      "2. Shrimp and Bacon Sauerkraut: Add cooked shrimp and crispy bacon to sauerkraut for a flavorful and protein-packed side dish. Serve with grilled sausages or pork chops for a classic German meal.\n",
      "\n",
      "3. Bacon and Shrimp Potato Salad: Add cooked shrimp and crispy bacon to a classic German potato salad for a delicious twist on a traditional dish. The smoky bacon and sweet shrimp will add depth of flavor to the creamy potato salad.\n",
      "\n",
      "4. Shrimp and Bacon Schnitzel: Top a crispy schnitzel with cooked shrimp and crispy bacon for a decadent and flavorful meal. Serve with a side of spaetzle or potato salad for a complete German feast.\n",
      "\n",
      "5. Bacon and Shrimp Bratwurst: Mix cooked shrimp and crispy bacon into the bratwurst mixture before grilling for a unique and delicious twist on a classic German sausage. Serve on a bun with sauerkraut and mustard for a tasty and filling meal."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0)\n",
    "\n",
    "resp = chat(chat_prompt_with_values.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For token counting\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 0\n",
      "Prompt Tokens: 0\n",
      "Completion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Translate this sentence from English to French. I love programming.' additional_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
